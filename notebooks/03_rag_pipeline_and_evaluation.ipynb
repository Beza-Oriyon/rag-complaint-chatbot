{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc735ef2",
   "metadata": {},
   "source": [
    "Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c386b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sample collection with 13,000 vectors\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"vector_store/chroma_db\")\n",
    "\n",
    "collection = client.get_collection(name=\"complaints_sample\")\n",
    "\n",
    "print(f\"Loaded sample collection with {collection.count():,} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98946dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 6 chunks (average distance: 0.2964)\n",
      "\n",
      "- Complaint 13085699 (Credit Cards) - Chunk 3/3\n",
      "- Complaint 11699927 (Credit Cards) - Chunk 2/2\n",
      "- Complaint 11348756 (Credit Cards) - Chunk 10/13\n",
      "- Complaint 12303728 (Credit Cards) - Chunk 10/10\n",
      "- Complaint 11348756 (Credit Cards) - Chunk 2/13\n",
      "- Complaint 12380325 (Credit Cards) - Chunk 2/2\n"
     ]
    }
   ],
   "source": [
    "def retrieve(question, k=5, product_filter=None):\n",
    "    where = {\"product_category\": product_filter} if product_filter else None\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\", \"embeddings\"]\n",
    "    )\n",
    "    \n",
    "    context_chunks = []\n",
    "    sources = []\n",
    "    \n",
    "    for doc, meta, dist in zip(results['documents'][0], results['metadatas'][0], results['distances'][0]):\n",
    "        context_chunks.append(doc)\n",
    "        sources.append(f\"Complaint {meta['complaint_id']} ({meta['product_category']}) - Chunk {meta['chunk_index']+1}/{meta['total_chunks']}\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_chunks)\n",
    "    \n",
    "    print(f\"Retrieved {k} chunks (average distance: {sum(results['distances'][0])/k:.4f})\\n\")\n",
    "    for s in sources:\n",
    "        print(f\"- {s}\")\n",
    "    \n",
    "    return context, sources\n",
    "\n",
    "# Test\n",
    "context, sources = retrieve(\"Why are customers unhappy with credit card late fees?\", k=6, product_filter=\"Credit Cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa92cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tiny GPT-2 – instant (seconds)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bezaw\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 loaded successfully! Ready for testing.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"Loading tiny GPT-2 – instant (seconds)...\")\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 400,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"do_sample\": True,\n",
    "    },\n",
    "    device=-1  # Force CPU\n",
    ")\n",
    "\n",
    "print(\"GPT-2 loaded successfully! Ready for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a7988",
   "metadata": {},
   "source": [
    "Setup chromaDB Collection for Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556b322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are a financial analyst assistant for CrediTrust Financial. Your task is to answer questions about customer complaints using ONLY the provided context. \n",
    "\n",
    "Be concise, insightful, and evidence-based. Cite specific examples from the context. If the context does not contain enough information to answer the question, say: \"I don't have enough information from the complaints to answer this.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d81b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(question, k=6, product_filter=None):\n",
    "    context, sources = retrieve(question, k=k, product_filter=product_filter)\n",
    "    \n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    \n",
    "    # Generate answer with GPT-2\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Clean the response a bit\n",
    "    answer = response.strip()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"QUESTION:\", question)\n",
    "    print(\"=\"*80)\n",
    "    print(\"ANSWER:\\n\", answer)\n",
    "    print(\"=\"*80)\n",
    "    print(\"SOURCES:\")\n",
    "    for i, s in enumerate(sources, 1):\n",
    "        print(f\"{i}. {s}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return answer, sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8322dd2",
   "metadata": {},
   "source": [
    "Batch Load and Add(Memory-Safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d3ec87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 6 chunks (average distance: 0.2964)\n",
      "\n",
      "- Complaint 13085699 (Credit Cards) - Chunk 3/3\n",
      "- Complaint 11699927 (Credit Cards) - Chunk 2/2\n",
      "- Complaint 11348756 (Credit Cards) - Chunk 10/13\n",
      "- Complaint 12303728 (Credit Cards) - Chunk 10/10\n",
      "- Complaint 11348756 (Credit Cards) - Chunk 2/13\n",
      "- Complaint 12380325 (Credit Cards) - Chunk 2/2\n",
      "\n",
      "================================================================================\n",
      "QUESTION: Why are customers unhappy with credit card late fees?\n",
      "================================================================================\n",
      "ANSWER:\n",
      " You are a financial analyst assistant for CrediTrust Financial. Your task is to answer questions about customer complaints using ONLY the provided context. \n",
      "\n",
      "Be concise, insightful, and evidence-based. Cite specific examples from the context. If the context does not contain enough information to answer the question, say: \"I don't have enough information from the complaints to answer this.\"\n",
      "\n",
      "Context:\n",
      "is a deceptive practice. it appears that the sole purpose of it is to charge more late fees wrongfully and illicitly. as the consumer financial protection bureau ( cfpb ), it is exactly within your purview to stop this kind of deceptive practices.\n",
      "\n",
      "refused to help get the late fees waved. i pay my credit cards in full every month, this was a comenity bank error and i should not have to pay the late fees. this was all over a {$19.00} purchase. now they want me to pay {$80.00} in late fees.\n",
      "\n",
      "provisions enforced by the cfpb, and stated to that, according to the card act, creditors are required to provide justification of real processing costs when issuers impose late fees in excess of {$8.00}. assured me that american express encourages cardholders to \" have a voice. '' further, offered an alternative to my request to revise the {$29.00} late fee in an offer of miles added to my flyer account. i declined. i am disturbed by the predatory expansion of late fees, and by the liberal\n",
      "\n",
      "late fees. the way they do business is unfair and unethical.\n",
      "\n",
      "reflects no prior missed payments to the account in the entire payment history with the creditor, so i contacted in hopes that providing a reasonable explanation could allow me a reversal in this unusual occurrence in my history with the creditor. unfortunately, working with the customer support then later when the issue was still not resolved, i was told that the credit issuer in fact does not include language in the cardmember agreement addressing redress of late fees so, because of such\n",
      "\n",
      "about it. so i closed the card and they continued adding late fees on the card.\n",
      "\n",
      "Question: Why are customers unhappy with credit card late fees?\n",
      "\n",
      "Answer: The reason why people feel dissatisfied or frustrated at their current situation may be due primarily...to lack confidence regarding how much money will go into them after paying off any outstanding debt before being paid back; however there also may exist other factors which can affect these issues too - including some who simply cannot afford to make up those debts themselves but wish to take advantage thereof through savings accounts etc.\n",
      "================================================================================\n",
      "SOURCES:\n",
      "1. Complaint 13085699 (Credit Cards) - Chunk 3/3\n",
      "2. Complaint 11699927 (Credit Cards) - Chunk 2/2\n",
      "3. Complaint 11348756 (Credit Cards) - Chunk 10/13\n",
      "4. Complaint 12303728 (Credit Cards) - Chunk 10/10\n",
      "5. Complaint 11348756 (Credit Cards) - Chunk 2/13\n",
      "6. Complaint 12380325 (Credit Cards) - Chunk 2/2\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('You are a financial analyst assistant for CrediTrust Financial. Your task is to answer questions about customer complaints using ONLY the provided context. \\n\\nBe concise, insightful, and evidence-based. Cite specific examples from the context. If the context does not contain enough information to answer the question, say: \"I don\\'t have enough information from the complaints to answer this.\"\\n\\nContext:\\nis a deceptive practice. it appears that the sole purpose of it is to charge more late fees wrongfully and illicitly. as the consumer financial protection bureau ( cfpb ), it is exactly within your purview to stop this kind of deceptive practices.\\n\\nrefused to help get the late fees waved. i pay my credit cards in full every month, this was a comenity bank error and i should not have to pay the late fees. this was all over a {$19.00} purchase. now they want me to pay {$80.00} in late fees.\\n\\nprovisions enforced by the cfpb, and stated to that, according to the card act, creditors are required to provide justification of real processing costs when issuers impose late fees in excess of {$8.00}. assured me that american express encourages cardholders to \" have a voice. \\'\\' further, offered an alternative to my request to revise the {$29.00} late fee in an offer of miles added to my flyer account. i declined. i am disturbed by the predatory expansion of late fees, and by the liberal\\n\\nlate fees. the way they do business is unfair and unethical.\\n\\nreflects no prior missed payments to the account in the entire payment history with the creditor, so i contacted in hopes that providing a reasonable explanation could allow me a reversal in this unusual occurrence in my history with the creditor. unfortunately, working with the customer support then later when the issue was still not resolved, i was told that the credit issuer in fact does not include language in the cardmember agreement addressing redress of late fees so, because of such\\n\\nabout it. so i closed the card and they continued adding late fees on the card.\\n\\nQuestion: Why are customers unhappy with credit card late fees?\\n\\nAnswer: The reason why people feel dissatisfied or frustrated at their current situation may be due primarily...to lack confidence regarding how much money will go into them after paying off any outstanding debt before being paid back; however there also may exist other factors which can affect these issues too - including some who simply cannot afford to make up those debts themselves but wish to take advantage thereof through savings accounts etc.',\n",
       " ['Complaint 13085699 (Credit Cards) - Chunk 3/3',\n",
       "  'Complaint 11699927 (Credit Cards) - Chunk 2/2',\n",
       "  'Complaint 11348756 (Credit Cards) - Chunk 10/13',\n",
       "  'Complaint 12303728 (Credit Cards) - Chunk 10/10',\n",
       "  'Complaint 11348756 (Credit Cards) - Chunk 2/13',\n",
       "  'Complaint 12380325 (Credit Cards) - Chunk 2/2'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_answer(\n",
    "    question=\"Why are customers unhappy with credit card late fees?\",\n",
    "    k=6,\n",
    "    product_filter=\"Credit Cards\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a99fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legacy Arrow IPC format enabled\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['ARROW_PRE_0_15_IPC_FORMAT'] = '1'  # Allows legacy extension types\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = '1'  # Optional, avoids timezone warnings\n",
    "\n",
    "print(\"Legacy Arrow IPC format enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e69a4",
   "metadata": {},
   "source": [
    "Inspect the Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295601cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "realloc of size 251658240 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m parquet_path = \u001b[33m'\u001b[39m\u001b[33m../data/prebuilt/complaint_embeddings-001.parquet\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Change if needed, e.g., 'data/raw/...' or just the filename\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Read only the first 10 rows to inspect structure (safe for memory)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_preview = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mParquet file loaded successfully for preview\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_preview.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# (rows, columns)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:265\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[32m    259\u001b[39m     path,\n\u001b[32m    260\u001b[39m     filesystem,\n\u001b[32m    261\u001b[39m     storage_options=storage_options,\n\u001b[32m    262\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    263\u001b[39m )\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     pa_table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[32m    274\u001b[39m         filterwarnings(\n\u001b[32m    275\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    276\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmake_block is deprecated\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    277\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    278\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1899\u001b[39m, in \u001b[36mread_table\u001b[39m\u001b[34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, filesystem, filters, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[39m\n\u001b[32m   1885\u001b[39m     \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[32m   1886\u001b[39m     dataset = ParquetFile(\n\u001b[32m   1887\u001b[39m         source, read_dictionary=read_dictionary,\n\u001b[32m   1888\u001b[39m         binary_type=binary_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1896\u001b[39m         page_checksum_verification=page_checksum_verification,\n\u001b[32m   1897\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1899\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1900\u001b[39m \u001b[43m                    \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1538\u001b[39m, in \u001b[36mParquetDataset.read\u001b[39m\u001b[34m(self, columns, use_threads, use_pandas_metadata)\u001b[39m\n\u001b[32m   1530\u001b[39m         index_columns = [\n\u001b[32m   1531\u001b[39m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[32m   1532\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m   1533\u001b[39m         ]\n\u001b[32m   1534\u001b[39m         columns = (\n\u001b[32m   1535\u001b[39m             \u001b[38;5;28mlist\u001b[39m(columns) + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) - \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[32m   1536\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1540\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_threads\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[32m   1544\u001b[39m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[32m   1545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pyarrow\\_dataset.pyx:589\u001b[39m, in \u001b[36mpyarrow._dataset.Dataset.to_table\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pyarrow\\_dataset.pyx:3969\u001b[39m, in \u001b[36mpyarrow._dataset.Scanner.to_table\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pyarrow\\error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bezaw\\OneDrive\\Desktop\\10Acadamy-KAIM\\RAG-Compliant-Chatbot\\rag-complaint-chatbot\\venv\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowMemoryError\u001b[39m: realloc of size 251658240 failed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adjust the path if your file is in a different location\n",
    "parquet_path = '../data/prebuilt/complaint_embeddings-001.parquet'  # Change if needed, e.g., 'data/raw/...' or just the filename\n",
    "\n",
    "# Read only the first 10 rows to inspect structure (safe for memory)\n",
    "df_preview = pd.read_parquet(parquet_path, engine='pyarrow')\n",
    "\n",
    "print(\"Parquet file loaded successfully for preview\")\n",
    "print(f\"Shape: {df_preview.shape}\")  # (rows, columns)\n",
    "print(\"\\nColumns:\")\n",
    "print(df_preview.columns.tolist())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df_preview.dtypes)\n",
    "\n",
    "print(\"\\nFirst 2 rows sample:\")\n",
    "print(df_preview.head(2))\n",
    "\n",
    "# Show one full example of key columns\n",
    "print(\"\\nExample of first row key fields:\")\n",
    "print(\"Text chunk:\", df_preview.iloc[0]['text'][:500] + \"...\" if 'text' in df_preview.columns else \"No 'text' column\")\n",
    "if 'embedding' in df_preview.columns:\n",
    "    print(\"Embedding shape:\", len(df_preview.iloc[0]['embedding']))\n",
    "if 'metadata' in df_preview.columns:\n",
    "    print(\"Metadata:\", df_preview.iloc[0]['metadata'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
